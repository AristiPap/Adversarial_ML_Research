{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AristiPap/Thesis_Stuff/blob/main/FGSM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2YhgVpnoP0nQ",
        "outputId": "059e45a4-afd0-4b82-c149-9f816d338727"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.datasets import mnist, cifar10, cifar100\n",
        "import tensorflow.keras.layers as L\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "from random import randint\n",
        "import time\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOTYhmrRP8kH",
        "outputId": "1716cbca-fec3-4c7b-878a-f26acd36f1aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "WR-2xA7TbKrB"
      },
      "outputs": [],
      "source": [
        "DATASET = 'cifar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KcFPqzMQbSzL"
      },
      "outputs": [],
      "source": [
        "# Utility functions\n",
        "def print_shapes(x_train, x_test, y_train, y_test):\n",
        "  print(f\"x_train: {x_train.shape}\\n\"\\\n",
        "      f\"x_test: {x_test.shape}\\n\"\\\n",
        "      f\"y_train: {y_train.shape}\\n\"\\\n",
        "      f\"y_test: {y_test.shape}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEBmAJ3rP-hN",
        "outputId": "9162cb44-f9dd-4e52-d224-6a053ab75d66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train: (50000, 32, 32, 3)\n",
            "x_test: (10000, 32, 32, 3)\n",
            "y_train: (50000, 1)\n",
            "y_test: (10000, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# loading the dataset\n",
        "if DATASET == 'mnist':\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "else:\n",
        "  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "  \n",
        "print_shapes(x_train, x_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "1gNsL0gLQK7R"
      },
      "outputs": [],
      "source": [
        "# Cifar100\n",
        "labels = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle',\n",
        "                'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel',\n",
        "                'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock',\n",
        "                'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',\n",
        "                'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster',\n",
        "                'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
        "                'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
        "                'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
        "                'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
        "                'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
        "                'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
        "                'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
        "                'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
        "                'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
        "                'worm']\n",
        "\n",
        "# Cifar10\n",
        "#labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# MNIST\n",
        "#labels = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv2znZnrQNnT",
        "outputId": "4d73cd57-7b5f-428d-8cf5-46600e62a7b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shapes (10000, 32, 32, 3) (10000, 100) (50000, 32, 32, 3) (50000, 100)\n"
          ]
        }
      ],
      "source": [
        "# Pre-process data\n",
        "if DATASET == 'mnist':\n",
        "  img_rows, img_cols, channels =  28, 28, 1 \n",
        "else:\n",
        "  img_rows, img_cols, channels =  32, 32, 3\n",
        "\n",
        "num_classes = len(labels)\n",
        "\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "x_train = x_train.reshape((-1, img_rows, img_cols, channels))\n",
        "x_test = x_test.reshape((-1, img_rows, img_cols, channels))\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(\"Data shapes\", x_test.shape, y_test.shape, x_train.shape, y_train.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "VYOLfD1g8Dyh"
      },
      "outputs": [],
      "source": [
        "class MyCNN(Sequential):\n",
        "  def __init__(self,input_size,filter_size=128, kernel_size = (3,3), dropout_flg = True, dropout_rate = 0.3):\n",
        "    super(MyCNN, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.filter_size = filter_size\n",
        "    self.kernel_size = kernel_size\n",
        "    self.dropout_flg = dropout_flg\n",
        "    self.dropout_rate = dropout_rate\n",
        "\n",
        "    self.add(L.Conv2D(self.filter_size, kernel_size=self.kernel_size,padding='same', activation='relu', input_shape=self.input_size))\n",
        "    if dropout_flg:\n",
        "      self.add(L.Dropout(self.dropout_rate))\n",
        "    self.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    self.add(L.Conv2D(self.filter_size/2, kernel_size=self.kernel_size,padding='same', activation='relu',input_shape=self.input_size))\n",
        "    if dropout_flg:\n",
        "      self.add(L.Dropout(self.dropout_rate))\n",
        "    self.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    self.add(L.Conv2D(self.filter_size/2, kernel_size=self.kernel_size,padding='same', activation='relu'))\n",
        "    if dropout_flg:\n",
        "      self.add(L.Dropout(self.dropout_rate))\n",
        "    self.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    self.add(L.Conv2D(self.filter_size/2, kernel_size=self.kernel_size,padding='same', activation='relu'))\n",
        "    self.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    if dropout_flg:\n",
        "      self.add(L.Dropout(self.dropout_rate))\n",
        "      \n",
        "    self.add(L.Flatten())\n",
        "    self.add(L.Dense(32))\n",
        "    self.add(L.Dropout(0.2))\n",
        "    self.add(L.Dense(num_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "qEhW1ZScgotA"
      },
      "outputs": [],
      "source": [
        "# Create and fit model\n",
        "model = MyCNN((img_rows, img_cols, channels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "J3UB6_RbhGWN"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-q1TUSCQUJ1",
        "outputId": "da74a24e-b923-4fd2-f162-9425c04c7586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_cnn_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 128)       3584      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 16, 16, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 64)        73792     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 2, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                8224      \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 100)               3300      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 162,756\n",
            "Trainable params: 162,756\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zzcNi_JXPKX",
        "outputId": "6641579c-5148-4228-c910-5977109267a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "391/391 [==============================] - 367s 937ms/step - loss: 0.0081 - accuracy: 0.2958 - val_loss: 0.0076 - val_accuracy: 0.4683\n",
            "Epoch 2/8\n",
            "391/391 [==============================] - 370s 946ms/step - loss: 0.0066 - accuracy: 0.4736 - val_loss: 0.0066 - val_accuracy: 0.5494\n",
            "Epoch 3/8\n",
            "391/391 [==============================] - 369s 944ms/step - loss: 0.0059 - accuracy: 0.5437 - val_loss: 0.0062 - val_accuracy: 0.5935\n",
            "Epoch 4/8\n",
            "391/391 [==============================] - 366s 936ms/step - loss: 0.0054 - accuracy: 0.5877 - val_loss: 0.0057 - val_accuracy: 0.6206\n",
            "Epoch 5/8\n",
            "391/391 [==============================] - 368s 941ms/step - loss: 0.0051 - accuracy: 0.6145 - val_loss: 0.0054 - val_accuracy: 0.6452\n",
            "Epoch 6/8\n",
            "391/391 [==============================] - 368s 942ms/step - loss: 0.0048 - accuracy: 0.6424 - val_loss: 0.0051 - val_accuracy: 0.6730\n",
            "Epoch 7/8\n",
            "391/391 [==============================] - 375s 960ms/step - loss: 0.0045 - accuracy: 0.6641 - val_loss: 0.0050 - val_accuracy: 0.6719\n",
            "Epoch 8/8\n",
            "  5/391 [..............................] - ETA: 5:52 - loss: 0.0044 - accuracy: 0.6703"
          ]
        }
      ],
      "source": [
        "train_history = model.fit(x_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=8,\n",
        "          validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgJQ60FIosu4"
      },
      "outputs": [],
      "source": [
        "def _plot(history = train_history):\n",
        "  fig, axis = plt.subplots(2, 2,figsize=(20, 8))\n",
        "  # plotting loss\n",
        "  axis[0,0].plot(train_history.history['loss'], label=\"loss\",color='red')\n",
        "  axis[0, 0].set_title(\"Loss per epoch for training set\")\n",
        "  axis[0,1].plot(train_history.history['val_loss'], label=\"val_loss\",color='red')\n",
        "  axis[0, 1].set_title(\"Loss per epoch for validation set\")\n",
        "  # plotting accuracy\n",
        "  axis[1,0].plot(train_history.history['accuracy'], label=\"accuracy\",color='green')\n",
        "  axis[1, 0].set_title(\"Accuracy per epoch for training set\")\n",
        "  axis[1,1].plot(train_history.history['val_accuracy'], label=\"val_accuracy\",color='green')\n",
        "  axis[1, 1].set_title(\"Accuracy per epoch for validation set\")\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqDbg1vOq-wb"
      },
      "outputs": [],
      "source": [
        "_plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEVVBJY-XRGP"
      },
      "outputs": [],
      "source": [
        "# Assess base model accuracy on regular images\n",
        "print(\"Base accuracy on regular images:\", model.evaluate(x=x_test, y=y_test, verbose=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FM5VBcPPOmOA"
      },
      "outputs": [],
      "source": [
        "folder_id = time.strftime('[%d%m%Y]_%H%M%s', time.localtime())\n",
        "dir_path = \"/content/drive/MyDrive/Thesis_notebooks/keras_boundary_attack/images\"\n",
        "os.mkdir(os.path.join(dir_path, folder_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Qonq8JTtRuG"
      },
      "outputs": [],
      "source": [
        "def process_img(image,adversarial_label,squeeze = False, folder = folder_id):\n",
        "  \"\"\"Export image file.\"\"\"\n",
        "  label = adversarial_label\n",
        "  print(\"Labeling from function\",label)\n",
        "  \n",
        "  cmap = plt.cm.jet\n",
        "  id_no = time.strftime('%Y%m%d_%H%M%S', datetime.datetime.now().timetuple())\n",
        "  if DATASET == 'mnist':\n",
        "    norm = plt.Normalize(vmin=image.reshape((img_rows, img_cols)).min(), vmax=image.reshape((img_rows, img_cols)).max())\n",
        "    # map the normalized data to colors\n",
        "    # image is now RGBA (512x512x4) \n",
        "    _image = cmap(norm(image.reshape((img_rows, img_cols))))\n",
        "    # Save with predicted label for image (may not be adversarial due to uint8 conversion)\n",
        "    plt.imsave(os.path.join(\"/content/drive/MyDrive/Thesis_notebooks/keras_boundary_attack/images\", folder,\"{}_{}.png\".format(id_no, label)), _image)\n",
        "\n",
        "  else:\n",
        "    plt.figure(figsize=(3,3))\n",
        "    _image = (1/(2*1.050000000745058)) * image + 0.35\n",
        "    print(np.max(image))\n",
        "    plt.imsave(os.path.join(\"/content/drive/MyDrive/Thesis_notebooks/keras_boundary_attack/images\", folder,\"{}_{}.png\".format(id_no, label)),_image.reshape(img_rows, img_cols, channels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jmenDb_zV_y"
      },
      "outputs": [],
      "source": [
        "def clip_eps(tensor, eps):\n",
        "\t# clip the values of the tensor to a given range and return it\n",
        "\treturn tf.clip_by_value(tensor, clip_value_min=-eps,clip_value_max=eps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsomeZ_Py1N1"
      },
      "outputs": [],
      "source": [
        "EPS = 2 / 255.0\n",
        "LR = 0.1\n",
        "optimizer = Adam(learning_rate=LR)\n",
        "sccLoss = SparseCategoricalCrossentropy()\n",
        "losses_per_image = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StqHmufbv_WI"
      },
      "outputs": [],
      "source": [
        "def generate_adversaries(model, baseImage, label, epochs=50):\n",
        "  \n",
        "  # iterate over the number of steps\n",
        "  for step in range(0, epochs):\n",
        "    baseImage = tf.cast(baseImage, tf.float32)\n",
        "    delta = tf.Variable(tf.zeros_like(baseImage), trainable=True)\n",
        "    # explicitly indicate that our perturbation vector should\n",
        " \t\t# be tracked for gradient updates\n",
        "    with tf.GradientTape() as tape:\n",
        "      tape.watch(baseImage)\n",
        "      # add our perturbation vector to the base image\n",
        "      adversary = baseImage + delta\n",
        "      # run this newly constructed image tensor through our\n",
        " \t\t\t# model and calculate the loss\n",
        "      pred = model(adversary)\n",
        "      loss = tf.keras.losses.MSE(label, pred)\n",
        "      # if step % 5 == 0:\n",
        "      #    print(\"step: {}, loss: {}...\".format(step,loss[0])) \n",
        "\n",
        "    # update the weights, clip the perturbation vector, and\n",
        " \t\t# update its value\n",
        "    gradients = tape.gradient(loss, baseImage)\n",
        "    delta.assign_add(clip_eps(delta, eps = EPS))\n",
        "    optimizer.apply_gradients([(gradients,delta)])\n",
        "    signed_grad = tf.sign(gradients)\n",
        "\n",
        "  losses_per_image.append(loss[0])\n",
        "  return signed_grad\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnDa3gGuXXr5"
      },
      "outputs": [],
      "source": [
        "# Create a signle adversarial example\n",
        "rand_idx = randint(0,49999)\n",
        "print(rand_idx)\n",
        "image = x_train[rand_idx]\n",
        "image_label = y_train[rand_idx]\n",
        "\n",
        "baseImage = tf.constant(image, dtype=tf.float32)\n",
        "delta = tf.Variable(tf.zeros_like(baseImage), trainable=True)\n",
        "\n",
        "print(\"[INFO] generating perturbation...\")\n",
        "deltaUpdated = generate_adversaries(model, image.reshape((1, img_rows, img_cols, channels)),image_label).numpy()\n",
        "\n",
        "#perturbations = adversarial_pattern(image.reshape((1, img_rows, img_cols, channels)), image_label).numpy()\n",
        "adversarial = image + deltaUpdated * 0.05\n",
        "\n",
        "print(labels[model.predict(image.reshape((1, img_rows, img_cols, channels))).argmax()])\n",
        "print(labels[model.predict(adversarial).argmax()])\n",
        "\n",
        "if channels == 1:\n",
        "    process_img(adversarial.reshape((img_rows, img_cols)),labels[model.predict(adversarial).argmax()])\n",
        "else:\n",
        "    #plt.imshow(adversarial.reshape((img_rows, img_cols, channels)))\n",
        "    if DATASET== 'mnist':\n",
        "      process_img(adversarial.reshape((img_rows, img_cols, channels)),labels[model.predict(adversarial).argmax()])\n",
        "    else:\n",
        "      process_img(adversarial,labels[model.predict(adversarial).argmax()])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "\n",
        "# rand_idx = 31797#random.randint(0,49999)\n",
        "# _image = x_train[rand_idx]\n",
        "# image_label = y_train[rand_idx]\n",
        "# print(rand_idx)\n",
        "# if DATASET == 'mnist':\n",
        "#   process_img(_image.reshape((img_rows, img_cols, channels)), image_label)\n",
        "# else:\n",
        "#   process_img(_image,image_label)"
      ],
      "metadata": {
        "id": "7ddllCjk4nBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8e69A2TkQJ_"
      },
      "outputs": [],
      "source": [
        "# rand_idx = randint(0,49999)\n",
        "# image = x_train[rand_idx].reshape((1, img_rows, img_cols, channels))\n",
        "# label = y_train[rand_idx]\n",
        "\n",
        "# print(f'Prediction from CNN: {labels[np.where(image_label==1)[0][0]]}')\n",
        "# plt.figure(figsize=(3,3))\n",
        "# if DATASET == 'mnist':\n",
        "#   plt.imsave('test.png',image.reshape((img_rows, img_cols, channels)))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6x5uEFHVX9p5"
      },
      "outputs": [],
      "source": [
        "# # Comparing both images \n",
        "# fig, (ax1,ax2) = plt.subplots(1, 2, sharey=True)\n",
        "# ax1.imshow(image.reshape(img_rows, img_cols, channels))\n",
        "# ax1.set_title(\"Original Image\")\n",
        "# ax2.imshow(adversarial.reshape(img_rows, img_cols, channels))\n",
        "# ax2.set_title(\"Image with Adversary\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ctr_non_misclassified = 0\n",
        "ctr_misclassified = 0"
      ],
      "metadata": {
        "id": "aK4_zPzEX-NS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3RgxGLIXbfv"
      },
      "outputs": [],
      "source": [
        "# Adversarial data generator\n",
        "def generate_adversarials(model, batch_size, stats = False):\n",
        "    while True:\n",
        "        x = []\n",
        "        y = []\n",
        "        true_images = []\n",
        "        for batch in range(batch_size):\n",
        "            N = random.randint(0, 100)\n",
        "\n",
        "            label = y_train[N]\n",
        "            image = x_train[N]\n",
        "            true_images.append(image)\n",
        "\n",
        "            perturbations = generate_adversaries(model, image.reshape((1, img_rows, img_cols, channels)), label).numpy()\n",
        "            \n",
        "            \n",
        "            epsilon = 0.1\n",
        "            adversarial = image + perturbations * epsilon\n",
        "            \n",
        "            x.append(adversarial)\n",
        "            y.append(y_train[N])\n",
        "        \n",
        "        \n",
        "        x = np.asarray(x).reshape((batch_size, img_rows, img_cols, channels))\n",
        "        y = np.asarray(y) #labels\n",
        "        true_images = np.asarray(true_images).reshape((batch_size, img_rows, img_cols, channels))\n",
        "        \n",
        "        if stats:\n",
        "          adversarials, correct_labels = x, y\n",
        "          for adversarial, correct_label, image in zip(adversarials, correct_labels, true_images):\n",
        "              print('Prediction:', labels[model.predict(adversarial.reshape((1, img_rows, img_cols, channels))).argmax()], 'Truth:', labels[correct_label.argmax()])\n",
        "              if channels == 1:\n",
        "                  tmp_label = labels[model.predict(adversarial.reshape((1, img_rows, img_cols, channels))).argmax()]\n",
        "              else:\n",
        "                  tmp_label = labels[model.predict(adversarial.reshape((1, img_rows, img_cols, channels))).argmax()]\n",
        "              \n",
        "              if tmp_label == labels[correct_label.argmax()]:\n",
        "                ctr_non_misclassified += 1\n",
        "              else:\n",
        "                ctr_misclassified += 1\n",
        "\n",
        "        yield x, y, true_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8FMqcY7Xcur"
      },
      "outputs": [],
      "source": [
        "# Generate and visualize 12 adversarial images\n",
        "adversarials, correct_labels, true_images = next(generate_adversarials(model,20))\n",
        "for adversarial, correct_label, image in zip(adversarials, correct_labels, true_images):\n",
        "    print('Prediction:', labels[model.predict(adversarial.reshape((1, img_rows, img_cols, channels))).argmax()], 'Truth:', labels[correct_label.argmax()])\n",
        "    if channels == 1:\n",
        "        tmp_label = labels[model.predict(adversarial.reshape((1, img_rows, img_cols, channels))).argmax()]\n",
        "        process_img(image.reshape(img_rows, img_cols, channels),labels[correct_label.argmax()])\n",
        "        process_img(adversarial.reshape((img_rows, img_cols)),tmp_label)\n",
        "        #plt.imshow(adversarial.reshape(img_rows, img_cols))\n",
        "    else:\n",
        "        tmp_label = labels[model.predict(adversarial.reshape((1, img_rows, img_cols, channels))).argmax()]\n",
        "        process_img(adversarial,tmp_label)\n",
        "        #plt.imshow(adversarial)\n",
        "\n",
        "        fig, (ax1,ax2) = plt.subplots(1, 2, sharey=True)\n",
        "        ax1.imshow(image.reshape(img_rows, img_cols, channels))\n",
        "        ax1.set_title(\"Original Image \"+labels[correct_label.argmax()])\n",
        "        ax2.imshow(adversarial.reshape(img_rows, img_cols, channels))\n",
        "        ax2.set_title(\"Image with Adversary \"+tmp_label)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpxZC-FrXhCh"
      },
      "outputs": [],
      "source": [
        "# Generate adversarial data\n",
        "# x_adversarial, y_adversarial = np.load(\"x_adv_10k.npy\"), np.load(\"y_adv_10k.npy\")\n",
        "x_adversarial_train, y_adversarial_train,_ = next(generate_adversarials(model,2000))\n",
        "x_adversarial_test, y_adversarial_test,_ = next(generate_adversarials(model,1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBsiudRWXjop"
      },
      "outputs": [],
      "source": [
        "# Assess base model on adversarial data\n",
        "print(\"Base accuracy on adversarial images:\", model.evaluate(x=x_adversarial_test, y=y_adversarial_test, verbose=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3nRqHICXmXT"
      },
      "outputs": [],
      "source": [
        "# Learn from adversarial data\n",
        "model.fit(x_adversarial_train, y_adversarial_train,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "          validation_data=(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzpH1GALXqBe"
      },
      "outputs": [],
      "source": [
        "# Assess defended model on adversarial data\n",
        "print(\"Defended accuracy on adversarial images:\", model.evaluate(x=x_adversarial_test, y=y_adversarial_test, verbose=0))\n",
        "\n",
        "# Assess defended model on regular data\n",
        "print(\"Defended accuracy on regular images:\", model.evaluate(x=x_test, y=y_test, verbose=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3i1cZGAXskp"
      },
      "outputs": [],
      "source": [
        "x_adversarial_test, y_adversarial_test, _ = next(generate_adversarials(model, 10))\n",
        "print(\"Defended accuracy on adversarial images:\", model.evaluate(x=x_adversarial_test, y=y_adversarial_test, verbose=0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missclassified images:\", ctr_misclassified)\n",
        "print(\"Non Missclassified images:\", ctr_non_misclassified)"
      ],
      "metadata": {
        "id": "_0MKkR49bPDZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyOiWIQnNZ3VsWYG+fTju8GI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}