{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOys3snrUdiXeag1ler0c9m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AristiPap/Thesis_Stuff/blob/main/BoundaryAttack_Hybrid_Diffe_Bounds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "from concurrent import futures\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "from __future__ import print_function\n",
        "try:\n",
        "\traw_input\n",
        "except:\n",
        "\traw_input = input\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from PIL import Image\n",
        "import sys\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "RESNET_MEAN = np.array([103.939, 116.779, 123.68])"
      ],
      "metadata": {
        "id": "LZde-V6m6kuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjdEUAQH6kV6",
        "outputId": "336f8375-f3e2-45bb-eee4-8ad618542541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sphere_perturbation(delta, prev_sample, target_sample):\n",
        "    \"\"\"Generate orthogonal perturbation.\"\"\"\n",
        "    perturb = np.random.randn(1, 224, 224, 3)\n",
        "    perturb /= np.linalg.norm(perturb, axis=(1, 2))\n",
        "    perturb *= delta * np.mean(get_diff(target_sample, prev_sample))\n",
        "    # Project perturbation onto sphere around target\n",
        "    # Orthorgonal vector to sphere surface\n",
        "    diff = (target_sample - prev_sample).astype(np.float32)\n",
        "    diff /= get_diff(target_sample, prev_sample)  # Orthogonal unit vector\n",
        "    # We project onto the orthogonal then subtract from perturb\n",
        "    # to get projection onto sphere surface\n",
        "    perturb -= (np.vdot(perturb, diff) / np.linalg.norm(diff)**2) * diff\n",
        "    # Check overflow and underflow\n",
        "    overflow = (prev_sample + perturb) - 255 + RESNET_MEAN\n",
        "    perturb -= overflow * (overflow > 0)\n",
        "    underflow = -RESNET_MEAN\n",
        "    perturb += underflow * (underflow > 0)\n",
        "    return perturb"
      ],
      "metadata": {
        "id": "EQygP6qX9l4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_perturbation(epsilon, prev_sample, target_sample):\n",
        "    \"\"\"Generate forward perturbation.\"\"\"\n",
        "    perturb = (target_sample - prev_sample).astype(np.float32)\n",
        "    perturb /= get_diff(target_sample, prev_sample)\n",
        "    perturb *= epsilon\n",
        "    return perturb\n",
        "\n",
        "\n",
        "def get_converted_prediction(sample, classifier):\n",
        "    \"\"\"\n",
        "    The loss of precision often causes the label of the image to change, particularly\n",
        "    because we are very close to the boundary of the two classes.\n",
        "    This function checks for the label of the exported sample\n",
        "    by simulating the export process.\n",
        "    \"\"\"\n",
        "    #sample = (sample + RESNET_MEAN).astype(np.uint8).astype(np.float32) - RESNET_MEAN\n",
        "    label = decode_predictions(classifier.predict(sample), top=1)[0][0][1]\n",
        "    return label\n",
        "\n",
        "\n",
        "def save_image(sample, classifier, folder):\n",
        "    \"\"\"Export image file.\"\"\"\n",
        "    label = get_converted_prediction(np.copy(sample), classifier)\n",
        "    print(\"Labeling from function\",label)\n",
        "    sample = sample.reshape(224, 224, 3)\n",
        "    # Reverse preprocessing, see https://github.com/keras-team/keras/blob/master/keras/applications/imagenet_utils.py\n",
        "    mean = [103.939, 116.779, 123.68]\n",
        "    sample[..., 0] += mean[0]\n",
        "    sample[..., 1] += mean[1]\n",
        "    sample[..., 2] += mean[2]\n",
        "    sample = sample[..., ::-1].astype(np.uint8)\n",
        "    # Convert array to image and save\n",
        "    sample = Image.fromarray(sample)\n",
        "    id_no = time.strftime('%Y%m%d_%H%M%S', datetime.datetime.now().timetuple())\n",
        "    # Save with predicted label for image (may not be adversarial due to uint8 conversion)\n",
        "    sample.save(os.path.join(\"/content/drive/MyDrive/Thesis_notebooks/my_boundary_attack/boundary-attack-master/images\", folder,\"{}_{}.png\".format(id_no, label)))\n",
        "\n",
        "#preprocessing with keras\n",
        "def preprocess(sample_path):\n",
        "    \"\"\"Load and preprocess image file.\"\"\"\n",
        "    img = image.load_img(sample_path, target_size=(224, 224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    return x\n",
        "\n",
        "#keep mean error for each iteration\n",
        "def get_diff(sample_1, sample_2):\n",
        "    \"\"\"Channel-wise norm of difference between samples.\"\"\"\n",
        "    sample_1 = sample_1.reshape(3, 224, 224)\n",
        "    sample_2 = sample_2.reshape(3, 224, 224)\n",
        "    diff = []\n",
        "    for i, channel in enumerate(sample_1):\n",
        "      diff.append(np.linalg.norm((channel - sample_2[i]).astype(np.float32)))\n",
        "    return np.array(diff)\n",
        "    #return np.linalg.norm(sample_1 - sample_2, axis=(1, 2))"
      ],
      "metadata": {
        "id": "YpdjhV9r9riJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCNN(Sequential):\n",
        "  def __init__(self,input_size,filter_size=128, kernel_size = (3,3), dropout_flg = True, dropout_rate = 0.3):\n",
        "    super(MyCNN, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.filter_size = filter_size\n",
        "    self.kernel_size = kernel_size\n",
        "    self.dropout_flg = dropout_flg\n",
        "    self.dropout_rate = dropout_rate\n",
        "\n",
        "    self.add(L.Conv2D(self.filter_size, kernel_size=self.kernel_size,padding='same', activation='relu', input_shape=self.input_size))\n",
        "    if dropout_flg:\n",
        "      self.add(L.Dropout(self.dropout_rate))\n",
        "    self.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    self.add(L.Conv2D(self.filter_size/2, kernel_size=self.kernel_size,padding='same', activation='relu',input_shape=self.input_size))\n",
        "    if dropout_flg:\n",
        "      self.add(L.Dropout(self.dropout_rate))\n",
        "    self.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    self.add(L.Conv2D(self.filter_size/2, kernel_size=self.kernel_size,padding='same', activation='relu'))\n",
        "    if dropout_flg:\n",
        "      self.add(L.Dropout(self.dropout_rate))\n",
        "    self.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    self.add(L.Conv2D(self.filter_size/2, kernel_size=self.kernel_size,padding='same', activation='relu'))\n",
        "    self.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    if dropout_flg:\n",
        "      self.add(L.Dropout(self.dropout_rate))\n",
        "      \n",
        "    self.add(L.Flatten())\n",
        "    self.add(L.Dense(32))\n",
        "    self.add(L.Dropout(0.2))\n",
        "    self.add(L.Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "UGN-EU4FLph9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlVYxu9AxX0k"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial import distance\n",
        "\n",
        "class boundary_attack():\n",
        "  def __init__(self,init_sample_path,target_sample_path,dir_path):\n",
        "    # load the pre-trained ResNet50 model\n",
        "    print(\"[INFO] loading pre-trained ResNet50 model...\")\n",
        "    self.classifier = ResNet50(weights='imagenet')\n",
        "\n",
        "    #init paths and folders for the statistics\n",
        "    self.initial_sample = preprocess(init_sample_path)\n",
        "    self.target_sample = preprocess(target_sample_path)\n",
        "\n",
        "    self.predictions_initial_sample = decode_predictions(self.initial_sample, top=3)[0]\n",
        "    self.predictions_target_sample = decode_predictions(self.target_sample, top=3)[0]\n",
        "\n",
        "    \n",
        "\n",
        "    self.folder = time.strftime('[%d%m%Y]_%H%M%s', time.localtime())\n",
        "    os.mkdir(os.path.join(dir_path, self.folder))\n",
        "    save_image(np.copy(self.initial_sample), self.classifier, self.folder)\n",
        "    #classifier initialised with our picture (in this case picture of seal that you can faintly see behind the eel when the attack is executed)\n",
        "    self.attack_class = np.argmax(self.classifier.predict(self.initial_sample))\n",
        "    #Our target image is the eel.The who,e point is to create an image that looks almost exactly like the eel but has pertrubations \"inspired by the eel\", \n",
        "    #so that it's misclassified\n",
        "    self.target_class = np.argmax(self.classifier.predict(self.target_sample))\n",
        "\n",
        "    self.adversarial_sample = self.initial_sample\n",
        "    self.n_steps = 0\n",
        "    self.n_calls = 0\n",
        "    self.epsilon = 1.\n",
        "    self.delta = 0.1\n",
        "    self.errors = []\n",
        "    self.boundaries_found = 0\n",
        "    self.repetitions = 0\n",
        "    self.prev_dist = 0\n",
        "    self.no_bound_found = 0\n",
        "\n",
        "  def _attack(self):\n",
        "    # Move first step to the boundary\n",
        "    # get first adversarial point to begin initiating the attack \n",
        "    #this is the hybrid version, where we keep looping, till we find a closer adversarial point\n",
        "    while True:\n",
        "        trial_sample = self.adversarial_sample + forward_perturbation(self.epsilon, self.adversarial_sample, self.target_sample) - self.prev_dist\n",
        "        prediction = self.classifier.predict(trial_sample.reshape(1, 224, 224, 3))\n",
        "        self.n_calls += 1\n",
        "        dist = distance.euclidean(prediction, self.classifier.predict(self.target_sample)) \n",
        "   \n",
        "        if self.repetitions == 0:\n",
        "          self.prev_dist = dist\n",
        "        if dist < self.prev_dist:\n",
        "          print(\"FOUND CLOSER BOUNDARY\")\n",
        "          print(dist)\n",
        "        self.prev_dist = dist\n",
        "        if self.repetitions > 1000 or self.no_bound_found > 100:\n",
        "          break\n",
        "        if np.argmax(prediction) == self.attack_class:\n",
        "            self.adversarial_sample = trial_sample\n",
        "            print(\"Found another bound\")\n",
        "            self.boundaries_found += 1\n",
        "            #self.epsilon *= 0.9\n",
        "        else:\n",
        "          print(\"Didn't Find bound\")\n",
        "          self.epsilon *= 0.9\n",
        "          self.no_bound_found += 1\n",
        "          break\n",
        "        self.repetitions += 1\n",
        "    # Iteratively run attack\n",
        "    while True:\n",
        "        print(\"Step #{}...\".format(self.n_steps))\n",
        "        # Orthogonal step\n",
        "        print(\"\\tDelta step...\")\n",
        "        d_step = 0\n",
        "        while True:\n",
        "            d_step += 1\n",
        "            print(\"\\t#{}\".format(d_step))\n",
        "            trial_samples = []\n",
        "            for i in np.arange(10):\n",
        "                trial_sample = self.adversarial_sample + sphere_perturbation(self.delta, self.adversarial_sample, self.target_sample)\n",
        "                trial_samples.append(trial_sample)\n",
        "            \n",
        "            trial_samples = np.asarray(trial_samples).reshape((-1,224,224,3))\n",
        "            predictions = self.classifier.predict(trial_samples)\n",
        "            self.n_calls += 10\n",
        "            predictions = np.argmax(predictions, axis=1)\n",
        "            d_score = np.mean(predictions == self.attack_class)\n",
        "            if d_score > 0.0:\n",
        "                if d_score < 0.3:\n",
        "                    self.delta *= 0.9\n",
        "                elif d_score > 0.7:\n",
        "                    self.delta /= 0.9\n",
        "                self.adversarial_sample = np.array(trial_samples)[np.where(predictions == self.attack_class)[0][0]]\n",
        "                break\n",
        "            else:\n",
        "                self.delta *= 0.9\n",
        "        # Forward step\n",
        "        print(\"\\tEpsilon step...\")\n",
        "        e_step = 0\n",
        "        while True:\n",
        "            e_step += 1\n",
        "            print(\"\\t#{}\".format(e_step))\n",
        "            trial_sample = self.adversarial_sample + forward_perturbation(self.epsilon, self.adversarial_sample, self.target_sample)\n",
        "            prediction = self.classifier.predict(trial_sample)\n",
        "            self.n_calls += 1\n",
        "            #adversarial step\n",
        "            if np.argmax(prediction) == self.attack_class:\n",
        "                temp = get_converted_prediction(np.copy(trial_sample), self.classifier)\n",
        "                print(temp)\n",
        "                self.adversarial_sample = trial_sample\n",
        "                self.epsilon /= 0.5\n",
        "                break\n",
        "            elif e_step > 500:\n",
        "                break\n",
        "            else:\n",
        "                self.epsilon *= 0.5\n",
        "\n",
        "        self.n_steps += 1\n",
        "        # keep some checkpoints so that we save the pictures whilst the attack progresses\n",
        "        chkpts = [250, 750]\n",
        "        if self.n_steps % 10 == 0:# in chkpts:\n",
        "            print(\"{} steps\".format(self.n_steps))\n",
        "            save_image(np.copy(self.adversarial_sample), self.classifier, self.folder)\n",
        "        diff = np.mean(get_diff(self.adversarial_sample, self.target_sample))\n",
        "        self.errors.append(diff)\n",
        "        #stop at 1000 steps ~= 40 minutes\n",
        "        if diff <= 1e-3 or e_step > 500 or self.n_steps > 7000:\n",
        "            print(\"{} steps\".format(self.n_steps))\n",
        "            print(\"Mean Squared Error: {}\".format(diff))\n",
        "            save_image(np.copy(self.adversarial_sample), self.classifier, self.folder)\n",
        "            break\n",
        "\n",
        "        print(\"Mean Squared Error: {}\".format(diff))\n",
        "        print(\"Calls: {}\".format(self.n_calls))\n",
        "        print(\"Attack Class: {}\".format(self.attack_class))\n",
        "        print(\"Target Class: {}\".format(self.target_class))\n",
        "        print(\"Adversarial Class: {}\".format(np.argmax(prediction)))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "init_path = '/content/drive/MyDrive/Thesis_notebooks/my_boundary_attack/boundary-attack-master/images/original/awkward_moment_seal.png'\n",
        "target_path ='/content/drive/MyDrive/Thesis_notebooks/my_boundary_attack/boundary-attack-master/images/original/bad_joke_eel.png'\n",
        "_dir_path = \"/content/drive/MyDrive/Thesis_notebooks/my_boundary_attack/boundary-attack-master/images\"\n",
        "model = boundary_attack(init_path,target_path,_dir_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "VAw07uc3c7kP",
        "outputId": "ec631d9f-a9f1-4f79-e5ba-7caca378fe00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading pre-trained ResNet50 model...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 1s 0us/step\n",
            "102981632/102967424 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-55ba4d0da010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtarget_path\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Thesis_notebooks/my_boundary_attack/boundary-attack-master/images/original/bad_joke_eel.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m_dir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Thesis_notebooks/my_boundary_attack/boundary-attack-master/images\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboundary_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_dir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-e357cf8b490f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, init_sample_path, target_sample_path, dir_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_sample_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions_initial_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions_target_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/applications/resnet.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[0;34m(preds, top)\u001b[0m\n\u001b[1;32m    512\u001b[0m               'keras.applications.resnet.decode_predictions')\n\u001b[1;32m    513\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mimagenet_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[0;34m(preds, top)\u001b[0m\n\u001b[1;32m    148\u001b[0m                      \u001b[0;34m'a batch of predictions '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                      \u001b[0;34m'(i.e. a 2D array of shape (samples, 1000)). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                      'Found array with shape: ' + str(preds.shape))\n\u001b[0m\u001b[1;32m    151\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mCLASS_INDEX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     fpath = data_utils.get_file(\n",
            "\u001b[0;31mValueError\u001b[0m: `decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (1, 224, 224, 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model._attack()"
      ],
      "metadata": {
        "id": "SDrCWufbc_Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_data = list(range(0, len(model.errors)))\n",
        "y_data = model.errors\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "ax.plot(x_data, y_data)\n",
        "ax.set_xlabel('steps to complete')\n",
        "ax.set_ylabel('mse')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GeoOITEhEseI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}